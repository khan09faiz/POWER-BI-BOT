# ONGC Equipment Data Processing Pipeline - Simplified

A clean, maintainable data processing pipeline for ONGC equipment data that processes Excel files and prepares them for Power BI integration.

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ config/                 # Configuration management
â”‚   â”œâ”€â”€ config.py           # Central configuration settings
â”‚   â”œâ”€â”€ logger.py           # Simple logging utilities
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ utils/                  # Utility functions
â”‚   â”œâ”€â”€ memory.py           # Memory optimization utilities
â”‚   â”œâ”€â”€ io.py              # File I/O operations
â”‚   â”œâ”€â”€ combine.py         # Data combination utilities
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ steps/                  # Processing steps
â”‚   â”œâ”€â”€ load_data.py       # Load Excel files
â”‚   â”œâ”€â”€ reduce_memory.py   # Memory optimization
â”‚   â”œâ”€â”€ combine_data.py    # Combine datasets
â”‚   â”œâ”€â”€ save_data.py       # Save processed data
â”‚   â””â”€â”€ preprocess_main.py # Pipeline orchestrator
â”œâ”€â”€ logs/                   # Log files
â””â”€â”€ run_preprocessing.py    # CLI entry point
```

## ğŸš€ Quick Start

1. **Install dependencies:**
```bash
pip install -r requirements.txt
```

2. **Place Excel files in `dataset/raw/`**

3. **Run the pipeline:**
```bash
python src/run_preprocessing.py
```

## ğŸ’¡ Features

- **Simple & Clean**: Each module under 150 lines of code
- **Memory Optimized**: 35%+ memory reduction through dtype optimization
- **Multi-format Output**: Saves as CSV and Parquet
- **Comprehensive Reports**: Detailed processing statistics
- **Robust Error Handling**: Clear error messages and validation
- **Modular Design**: Easy to understand and maintain

## ğŸ“‹ Commands

```bash
# Run full pipeline
python src/run_preprocessing.py

# Validate setup
python src/run_preprocessing.py --validate

# Show pipeline info
python src/run_preprocessing.py --info
```

## ğŸ“Š Data Processing

The pipeline processes ONGC equipment data through these steps:

1. **Load Data**: Discovers and loads all Excel files
2. **Combine Data**: Concatenates files and filters required columns
3. **Optimize Memory**: Reduces memory usage through dtype optimization
4. **Save Results**: Outputs CSV, Parquet, and processing reports

## ğŸ¯ Output

- **Processed Data**: `dataset/processed/ongc_equipment_data_YYYYMMDD_HHMMSS.csv`
- **Optimized Data**: `dataset/processed/ongc_equipment_data_YYYYMMDD_HHMMSS.parquet`
- **Processing Report**: `reports/processing_report_YYYYMMDD_HHMMSS.json`
- **Logs**: `src/logs/preprocessing.log`

## âš™ï¸ Configuration

All settings are centralized in `src/config/config.py`:

- Required columns to extract
- Column name mappings
- Processing options
- Output formats

## ğŸ§¹ Code Quality

- Each file is under 150 lines of code
- Single responsibility principle
- Clear error handling
- Comprehensive logging
- No over-engineering
